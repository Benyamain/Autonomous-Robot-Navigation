I am thinking of testing the project on Gazebo, where if things turn out for the best, would suffice. Gazebo is software used for robot simulations. Of course, the narrative can change not only by being limited to simulation, but by applying it to physical constraints and dynamics, but that would bring a new way of approaching the framework (at least in terms of revising my current plan), which nothing is wrong with that, but I did not intend to produce that goal (the transfer of simulation to real-life).

Another great question as well, because it does consider how much time will be allocated to making this happen. So, we could build a robot, as in whoever decides to pursue this idea with me, or could lend some assistance from the CS department to buy a prebuilt robot? I do not think that would be necessary, I have seen robots that already have adequate sensors for the target goals we want from the robot. But, all under the notion we go without physical dynamics incorporated; I do not think this project would allow the time for that, given that the simulation aspect will take a good amount of time.

I like your way of thinking!! It is good to question the novelty of what comes from this project. Primarily, from what I have seen, on the 6 collective sources I read and skimmed, they have the reinforcement learning part and deep image segmentation part down very well, and whoever works on this with me, will gain inspiration from their techniques and be smart about our architecture.

However, I have not seen literature/academia cover reinforcement learning, image segmentation, AND a separate learning network for the ACTUAL robot itself. You might wonder what I mean by this, but the high-level explanation is that the robots have wheels we can fine-tune, or change, based on the goal it seeks to maximize (that we define), and from there, the wheel dynamics, steering, accelerating or velocity, can be changed and considered components of interest to the learning model.

This could mean a few different things: the robot is hesitant and jitters, who knows, or hopefully, how I see it occurring if the robot learns the correct 'threshold' to apply in certain situations where it is placed within the simulation environment. So, wheel turns, decelerating, etc, are valid actions that the additional learning model would integrate.

That is what literature has not explored ON TOP OF reinforcement learning and image segmentation. So, the framework is layered and they should intently bounce off each other, in terms of information exchange, and that is the novelty. Long response but I do not mind boring you with the details, also, I am open to people requesting to join :)